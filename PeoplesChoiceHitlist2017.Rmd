---
title: "PeoplesChoiceHitChart2017"
output: html_document
---
<br>

At the end of the year, everyone is making lists. And radio stations are no exceptions.  
Many of our radio stations have a weekly "people's choice" hit chart. Throughout the week, people submit their top 3 recent songs, and every week those votes turn into a hit chart. At the end of the year, they collapse all those weekly charts into a larger one covering the entire year.  
  
I find this one quite interesting: it's not dependent on what music people buy, it's determined by what the audience of that station wants to hear. So what are the differences between these stations? And do they match up with what I would expect?
  
<br>

## About the data
I took 4 different radio stations:

 * Radio 1: The most serious of our public broadcast stations. It's aimed at current affairs, politics, news, ... When I think of Radio 1 music, I think of Paul Simon, Aretha Franklin, Nathaniel Ratecliff and Elbow. 
 * Studio Brussels: Formerly known as the "rock station", but now it's really a mix of modern rock, pop, indie & dance music. 
 * MNM: Described as the "contemporary hit radio station" of the public broadcast organisation
 * Q music: A commercial "contemporary hit radio station"  

There is one major and annoying drawback in this dataset: Studio Brussels does a top 30, while all the others do a top 100. 

<br>

Loading all the packages needed:

```{r message=FALSE, warning=FALSE}
#for scraping
library(rvest)
library(xml2)
library(jsonlite)

#for cleanup and data manipulation
library(stringr)
library(dplyr)
library(tidyr)

#for graphing
library(ggplot2)
```
<br>




## Web Scraping Etiquette
Before starting the scrape, I wanted to make sure that I was allowed to do so using the rOpenSci robotstxt package:

```{r message=FALSE, warning=FALSE, results="hold"}
#Webscraping etiquette: am i allowed to scrape this site?
robotstxt::paths_allowed("https://stubru.be/music/arcadefireopeenindeafrekening2017")
robotstxt::paths_allowed("https://mnm.be/mnm50/dezesongstemdejijhetafgelopenjaartvaakstdemnm50")
robotstxt::paths_allowed("https://radio1.be/vox-100-de-lijst-2017")
robotstxt::paths_allowed("https://qmusic.be/hitlijsten/favoriete-100-2017")
```
<br>



## Bad luck with the standard scraping procedures...
A quick search showed no APIs for any of these websites, so I started with `rvest` and the usual CSS nodes routine. Unfortunately no CSS element or XPATH gave me any useful information.

```{r}
#usual method
read_html("https://stubru.be/music/arcadefireopeenindeafrekening2017") %>%
  html_nodes(css=".song-title")
```

The issue is that the website is rendered through Javascript, and R is scraping the website before the content is loaded. After a bit of googling I found [a tutorial](https://www.datacamp.com/community/tutorials/scraping-javascript-generated-data-with-r) that had all the answers I needed. 
<br>



## Scraping Javascript rendered websites
Through `phantomJS` you can create a representation of the website after Javascript loaded all the data. Afterwards you can scrape the local version.  
I opened a normal notepad and saved the following as `scrape_stubu.js`:

```
var webPage = require('webpage');
var page = webPage.create();

var fs = require('fs');
var path = 'scrape_stubru.html'

page.open('https://stubru.be/music/arcadefireopeenindeafrekening2017', function (status) {
  var content = page.content;
  fs.write(path,content,'w')
  phantom.exit();
});
```
<br>

Next, you use a `system` command in R to run the script and return a local html version. You need `phantomJS` installed to do this, but you can easily install it form [here](http://phantomjs.org/download.html).

```{r eval=FALSE}
#generate local copies of all required websites
system("./phantomjs/bin/phantomjs scrape_stubru.js")
system("./phantomjs/bin/phantomjs scrape_radio1.js")
system("./phantomjs/bin/phantomjs scrape_qmusic.js")
system("./phantomjs/bin/phantomjs scrape_mnm.js")
```
<br>

## Scraping the data

Many of the websites had quite similar structures so I wrote a function to extract the ranking, artist and title from the website and return it as a dataframe.
```{r}
#function to scrap info
scrape_music <- function(html, css_artist, css_title, css_ranking) {
  html_page <- read_html(html)
  
  #extracting song info
  artist <- html_page %>%
    html_nodes(css = css_artist) %>%
    html_text() %>%
    tolower()
  
  #extracting artist info
  title <- html_page %>%
    html_nodes(css = css_title) %>%
    html_text() %>%
    tolower()
  
  #extracting ranking
  ranking <- html_page %>%
    html_nodes(css = css_ranking) %>%
    html_text() %>%
    as.numeric()
  
  #making a dataframe
  df <- data.frame(ranking, artist, title, stringsAsFactors = FALSE)
  return(df)
}
```
<br>

Using the function above, three radio stations were easily scraped. Two of them needed no additional clean-up. Only Qmusic was a bit differently set up, and needed some stringr work to remove a few "/n" signs.
```{r}
#scraping studio brussels
stubru <- scrape_music(html = "scrape_stubru.html", css_artist = ".song-title",
                            css_title = ".song-name", css_ranking=".song-position")
colnames(stubru) <- c("stubru_ranking", "artist", "title")

#scraping mnm
mnm <- scrape_music(html = "scrape_mnm.html", css_artist = ".song-name",
                       css_title = ".song-title", css_ranking=".song-position")
colnames(mnm) <- c("mnm_ranking", "artist", "title")

#scraping mnm
qmusic <- scrape_music(html = "scrape_qmusic.html", css_artist = ".title-bar",
                    css_title = ".subtitle", css_ranking=".hitlist-position")
colnames(qmusic) <- c("qmusic_ranking", "artist", "title")
qmusic$artist <- str_replace_all(qmusic$artist, "\\\n", "")
qmusic$title <- str_replace_all(qmusic$title, "\\\n", "")
```
<br>

Radio 1 was by far the trickiest. Even after rendering it through `phantomJS` it kept returning no content in any of the CSS nodes referring to the table containing the hit chart. Digging in the `inspect element` view of the brower I found out that the table was sourced from yet another page, but even on that page phantomJS didn't do the job. (If anyone can tell me why, please do!)  
Luckily a few curses later, I discovered an API link in the source code of the webpage.  
I was about to skip Radio 1 all together, but there it was...

```{r}
library(jsonlite)
content2 <- fromJSON("https://hitlijst.vrt.be/api/lists/3594.json")
str(content2$songs, max.level=1)

title <- tolower(content2$songs$title)
artist <- tolower(content2$songs$name)
radio1_ranking <- as.numeric(content2$songs$position)

radio1 <- data.frame(radio1_ranking, title, artist, stringsAsFactors = FALSE)
```
<br>


## Comparing the radio stations

I wrote a short function that compares the two dataframes via `semi_join()` and then pastes a short sentence together with `paste`. Not the most ingenious solution, but fast and useful enough. 
  
```{r, results="hold", echo=FALSE}

compare_songs <- function(x, y, name.x, name.y, warning=NULL) {
  count <- x %>%
    semi_join(y, by="title") %>%
    count()
  
  paste0("Songs in common between ", name.x, " and ", name.y, ": ", count, warning)
}
```
<br>

## Radio 1

Regarding Radio 1, I would expect some moderate overlap with Studio Brussels because they have the softer indie and rock music in common. With the two pop hit

```{r, results="hold", echo=FALSE}
compare_songs(radio1, stubru, "Radio1", "Studio Brussels", " (out of 30)")
compare_songs(radio1, mnm, "Radio1", "MNM")
compare_songs(radio1, qmusic, "Radio1", "Qmusic")
```



```{r echo=FALSE}
#plotting stubru versus radio 1
radio1 %>%
  inner_join(stubru, by="title") %>%
  unite(combo, artist.x, title, sep=" - ") %>%
  ggplot(aes(x=radio1_ranking, y=stubru_ranking, label = combo))+
  geom_point(colour="cadetblue4") +
  scale_y_reverse(name = "Studio Brussels ranking") +
  scale_x_reverse(name = "Radio 1 ranking", limits=c(105,-10), breaks=c(0, 25, 50,75, 100)) +
  geom_text(vjust = 0, nudge_y = 0.5, colour="cadetblue4") +
  ggtitle("Comparing Radio 1 and Studio Brussels")
```

12 songs in common between Radio 1 and its sister-station where pophits rule (MNM), but none of them score really high for both audiences.  
Again another rap song is doing well for the radio 1 audience (Drake) though. 

```{r echo=FALSE}
#plotting stubru versus radio 1
radio1 %>%
  inner_join(mnm, by="title") %>%
  unite(combo, artist.x, title, sep=" - ") %>%
  ggplot(aes(x=radio1_ranking, y=mnm_ranking, label = combo))+
  geom_point(colour="cadetblue4") +
  scale_y_reverse(name = "MNM ranking") +
  scale_x_reverse(name = "Radio 1 ranking", limits=c(110,0), breaks=c(0, 25, 50,75, 100)) +
  geom_text(vjust = 0, nudge_y = 0.5, colour="cadetblue4") +
  ggtitle("Comparing Radio 1 and MNM")
```

The least overlap is between Radio 1 and the commerical hitradio Qmusic. I would have been stunned if it was any other way: 9 songs in common out of a 100, and none of those 9 are high in both hitlists. Rag'n'Bone man isthe highest finding itself about midway in both lists.

```{r echo=FALSE}
#plotting stubru versus radio 1
radio1 %>%
  inner_join(qmusic, by="title") %>%
  unite(combo, artist.x, title, sep=" - ") %>%
  ggplot(aes(x=radio1_ranking, y=qmusic_ranking, label = combo))+
  geom_point(colour="cadetblue4") +
  scale_y_reverse(name = "Qmusic ranking") +
  scale_x_reverse(name = "Radio 1 ranking", limits=c(110,0), breaks=c(0, 25, 50,75, 100)) +
  geom_text(vjust = 0, nudge_y = 0.5, colour="cadetblue4") +
  ggtitle("Comparing Radio 1 and Qmusic")
```


## Studio Brussels

As expected, there is most overlap between Studio Brussels and Radio1. Both pophit radios show less than 25% common songs.

```{r, results="hold", echo=FALSE}
compare_songs(stubru, radio1, "Studio Brussels", "Radio1", "(out of 30)")
compare_songs(stubru, mnm, "Studio Brussels", "MNM", "(out of 30)")
compare_songs(stubru, qmusic, "Studio Brussels", "Qmusic", "(out of 30)")
```


Versus the hitradios there are 5 to 7 songs in common. Ed Sheeran seems to do well everywhere. 

```{r echo=FALSE}
#plotting stubru versus radio 1
stubru %>%
  inner_join(mnm, by="title") %>%
  unite(combo, artist.x, title, sep=" - ") %>%
  ggplot(aes(x=stubru_ranking, y=mnm_ranking, label = combo))+
  geom_point(colour="cadetblue4") +
  scale_y_reverse(name = "MNM ranking") +
  scale_x_reverse(name = "Studio Brussels ranking", limits=c(35,0), breaks=c(0, 10, 20,30)) +
  geom_text(vjust = 0, nudge_y = 0.5, colour="cadetblue4") +
  ggtitle("Comparing Studio Brussels and MNM")
```



```{r echo=FALSE}
#plotting stubru versus radio 1
stubru %>%
  inner_join(qmusic, by="title") %>%
  unite(combo, artist.x, title, sep=" - ") %>%
  ggplot(aes(x=stubru_ranking, y=qmusic_ranking, label = combo))+
  geom_point(colour="cadetblue4") +
  scale_y_reverse(name = "Qmusic ranking") +
  scale_x_reverse(name = "Studio Brussels ranking", limits=c(35,0), breaks=c(0, 10, 20,30)) +
  geom_text(vjust = 0, nudge_y = 0.5, colour="cadetblue4") +
  ggtitle("Comparing Studio Brussels and Qmusic")
```



## MNM and Q-music

Lastly, both hit radios against each other: I'm expecting massive overlap between these two, but how massive exactly?  
Indeed a massive 61 songs in common.


```{r, results="hold", echo=FALSE}
compare_songs(mnm, qmusic, "MNM", "Qmusic")
compare_songs(mnm, radio1, "MNM", "Radio1")
compare_songs(mnm, stubru, "MNM", "Studio Brussels")
compare_songs(qmusic, radio1, "Qmusic", "Radio1")
compare_songs(qmusic, stubru, "Qmusic", "Studio Brussels")
```

So much overlap, it's hardly readable, and espcially the upper right corner is very populated, confirming that both audiences like the same 2017 songs.

```{r echo=FALSE}
#plotting stubru versus radio 1
mnm %>%
  inner_join(qmusic, by="title") %>%
  unite(combo, artist.x, title, sep=" - ") %>%
  ggplot(aes(x=mnm_ranking, y=qmusic_ranking, label = combo))+
  geom_point(colour="cadetblue4") +
  scale_y_reverse(name = "Qmusic ranking") +
  scale_x_reverse(name = "MNM ranking", limits=c(110,0), breaks=c(0, 25, 50,75, 100)) +
  geom_text(vjust = 0, nudge_y = 0.5, colour="cadetblue4") +
  ggtitle("Comparing MNM and Qmusic")
```
<br>

The biggest surprise for me is still the mystery of this Radio 1 list. Clearly I have no clue, even though I do listen to it on a weekly basis. I think my next project will be scraping the Radio 1 playlist just to understand what music they play when I'm not listenen...